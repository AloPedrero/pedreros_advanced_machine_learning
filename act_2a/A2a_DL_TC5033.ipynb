{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601b2309",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks using PyTorch\n",
    "<br>\n",
    "\n",
    "#### Activity 2a: Implementing a FC for ASL Dataset using PyTorch\n",
    "<br>\n",
    "\n",
    "\n",
    "- Objective\n",
    "\n",
    "    The primary aim of this activity is to transition from using Numpy for network implementation to utilizing PyTorch, a powerful deep learning framework. You will be replicating the work you did for the ASL dataset in Activity 1b, but this time, you'll implement a your multi layer FC model using PyTorch.\n",
    "    \n",
    "- Instructions\n",
    "\n",
    "    Review Previous Work: Begin by reviewing your Numpy-based Fully Connected Network for the ASL dataset from Activity 1b. Note the architecture, hyperparameters, and performance metrics for comparison.\n",
    "\n",
    "    Introduce PyTorch: If you're new to PyTorch, take some time to familiarize yourself with its basic operations and syntax. You can consult the official documentation or follow online tutorials.\n",
    "\n",
    "    Prepare the ASL Dataset: As before, download and preprocess the Kaggle ASL dataset. \n",
    "\n",
    "    Implement the Network: Design your network architecture tailored for the ASL dataset. Pay special attention to PyTorch modules like nn.Linear() and nn.ReLU().\n",
    "\n",
    "    Train the Model: Implement the training loop, making use of PyTorch's autograd to handle backpropagation. Monitor metrics like loss and accuracy as the model trains.\n",
    "\n",
    "    Analyze and Document: In Markdown cells, discuss the architecture choices, any differences in performance between the Numpy and PyTorch implementations, and insights gained from using a deep learning framework like PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "183db241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#PyTorch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Solamente para usuarios de Jupyter Themes\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3896ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
    "DATA_PATH = 'asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa938e",
   "metadata": {},
   "source": [
    "### Always a good idea to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c149b4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2d1df",
   "metadata": {},
   "source": [
    "### Get training label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4348519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c9bed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 784)\n",
      "(27455,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea87a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7172, 784) (7172,)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b7edd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    assert x.shape[0] == y.shape[0], 'Number of samples x!= number samples y'\n",
    "    total_samples = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(x.shape[0])\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        #return x_val, y_val, x_test, y_test\n",
    "#         return x[:total_samples//2, :], y[:total_samples//2], x[total_samples//2:, :], y[total_samples//2:]\n",
    "    return x[:int(total_samples*pct), :], y[:int(total_samples*pct)], x[int(total_samples*(pct)):, :], y[int(total_samples*(pct)):]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fb6fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7a02137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "986ec106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3586, 784) (3586,)\n",
      "(3586, 784) (3586,)\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d65bdf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17874be",
   "metadata": {},
   "source": [
    "### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0a5cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8cf6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0eef77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(3.6268384e-06), np.float32(0.99999946))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4761728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5eb103d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b9216b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_val))\n",
    "# print(rnd_idx)\n",
    "# print(y_val[rnd_idx])\n",
    "print(f'La imagen muestreada representa un: {alphabet[y_val[rnd_idx]]}')\n",
    "plot_number(x_val[rnd_idx].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cfc56",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c833b",
   "metadata": {},
   "source": [
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae3ef9",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "780beecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b8f845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(create_minibatches(128,x_train, y_train)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12273997",
   "metadata": {},
   "source": [
    "### Now the PyTorch part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbd1415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.copy())\n",
    "y_train_tensor = torch.tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val.copy())\n",
    "y_val_tensor = torch.tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.copy())\n",
    "y_test_tensor = torch.tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "087285a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c3ba5",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2e0f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    cost = 0.\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x, y),1):\n",
    "            xi = xi.to(device=device, dtype = torch.float32)\n",
    "            yi = yi.to(device=device, dtype = torch.long)\n",
    "            scores = model(xi) # mb_size, 10\n",
    "            cost += (F.cross_entropy(scores, yi)).item()\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "        return cost/mb, float(num_correct)/num_total  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c2954",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d0e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, mb_size, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    train_cost = 0.\n",
    "    val_cost = 0.\n",
    "    for epoch in range(epochs):\n",
    "        train_correct_num  = 0.\n",
    "        train_total = 0.\n",
    "        train_cost_acum = 0\n",
    "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x_train_tensor, y_train_tensor), 1):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            # funcion cost\n",
    "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            train_correct_num += (torch.argmax(scores, dim=1) == yi.squeeze()).sum()\n",
    "            train_total += scores.size(0)  \n",
    "            \n",
    "            train_cost_acum += cost.item()\n",
    "        \n",
    "        val_cost, val_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
    "        train_acc = float(train_correct_num)/train_total\n",
    "        train_cost = train_cost_acum/mb\n",
    "        if epoch%20 == 0:            \n",
    "            print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
    "                      f' train acc: {train_acc:.4f}, val acc: {val_acc:4f},'\n",
    "                      f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b9243",
   "metadata": {},
   "source": [
    "### Model using Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3d678e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, train cost: 0.886685, val cost: 0.732406, train acc: 0.7198, val acc: 0.773285, lr: 0.004000\n",
      "Epoch:20, train cost: 0.170922, val cost: 2.153271, train acc: 0.9623, val acc: 0.791411, lr: 0.004000\n",
      "Epoch:40, train cost: 0.177526, val cost: 2.440045, train acc: 0.9642, val acc: 0.801450, lr: 0.004000\n",
      "Epoch:60, train cost: 0.166143, val cost: 3.152598, train acc: 0.9684, val acc: 0.791132, lr: 0.004000\n",
      "Epoch:80, train cost: 0.156855, val cost: 2.857880, train acc: 0.9710, val acc: 0.771054, lr: 0.004000\n"
     ]
    }
   ],
   "source": [
    "#Instanciar modelo\n",
    "# hidden1 = 100 \n",
    "hidden = 200\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "mb_size = 128\n",
    "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden), \n",
    "                       nn.Dropout(),\n",
    "                       nn.ReLU(),\n",
    "#                        nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden, out_features=24))\n",
    "# optimiser = torch.optim.SGD(model1.parameters(), lr=lr, momentum=0.9, weight_decay=1e-2)\n",
    "optimiser = torch.optim.Adam(model1.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, 0.1, epochs=epochs, steps_per_epoch=215)\n",
    "\n",
    "train(model1, optimiser, mb_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1942c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7836029001673174"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model1, x_test_tensor, y_test_tensor, mb_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fa8f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, model):\n",
    "    x = x.to(device=device, dtype = torch.float32)\n",
    "    scores = model(x) # mb_size, 10\n",
    "    _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb4edc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: t\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor predicho t\n"
     ]
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {alphabet[y_test[rnd_idx]]}')\n",
    "plot_number(x_test[rnd_idx].reshape(28,28))\n",
    "pred=predict(x_test_tensor[rnd_idx].reshape(1, -1), model1)\n",
    "print(f'el valor predicho {alphabet[pred]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
