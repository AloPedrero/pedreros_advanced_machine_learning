{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "- Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
    "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#################################\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the training and validation datasets, without the label to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the validation entire data set in to test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    \"\"\"\n",
    "    Splits the input data (x, y) into validation and test sets based on a specified percentage.\n",
    "\n",
    "    If shuffle is True, the data is shuffled before splitting. The split is done by taking \n",
    "    the first portion of the data as the validation set and the remaining portion as the test set.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        indices = np.arange(x.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        x = x[indices]\n",
    "        y = y[indices]\n",
    "\n",
    "    split_index = int((1 - pct) * len(x))\n",
    "\n",
    "    x_val, x_test = x[:split_index], x[split_index:]\n",
    "    y_val, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "    return x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the movement nature of the J and Z letters, remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 24 == len(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    \"\"\"\n",
    "    Normalizes the input data by subtracting the mean and dividing by the standard deviation.\n",
    "    \"\"\"\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average and standard deviation from the normalized datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the standard deviation is almost perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(3.6268384e-06), np.float32(0.99999946))"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "  \"\"\"\n",
    "  Simple display of a given image in gray scale.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(5, 5))\n",
    "  plt.imshow(image.reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: c\n"
     ]
    }
   ],
   "source": [
    "# Let's jsut print a random image to see if it works...\n",
    "rnd_idx = np.random.randint(len(y_test))\n",
    "plot_image(x_test[rnd_idx])\n",
    "actual_char = alphabet[y_test[rnd_idx]]\n",
    "print(f\"Displaying: {actual_char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math ecuations for the model\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    \"\"\"\n",
    "    Creates minibatches from the input data (x, y) by splitting them into smaller batches of a specified size.\n",
    "\n",
    "    If shuffle is True, the data is shuffled before creating minibatches.\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0], 'Error: number of samples do not match'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Clase Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor class with `ndarray` properties via inheritance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "class np_tensor(np.ndarray): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the fully connected layer of the linear neural network that streamline the layers passed as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    \"\"\"\n",
    "    A class representing a linear layer in a neural network. \n",
    "\n",
    "    It initializes the weights and biases, performs the forward pass, \n",
    "    and computes the gradients during the backward pass.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "\n",
    "    def backward(self, X, Z):\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        self.b.grad = np.sum(Z.grad, axis = 1, keepdims=True)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple implementation the Rectified Linear Unit activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    A class representing the ReLU activation function.\n",
    "\n",
    "    It applies the ReLU function during the forward pass and computes the gradient during the backward pass.\n",
    "    \"\"\"\n",
    "    def __call__(self, Z):\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def backward(self, Z, A):\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    \"\"\"\n",
    "    A class that represents a sequence of layers in a neural network.\n",
    "\n",
    "    It handles the forward pass, backward pass, weight updates, and predictions by chaining multiple layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "\n",
    "    def __call__(self, X):\n",
    "        self.x = X \n",
    "        self.outputs['l0'] = self.x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l'+str(i)]=self.x\n",
    "        return self.x\n",
    "\n",
    "    def backward(self):\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            self.layers[i].backward(self.outputs['l'+str(i)], self.outputs['l'+str(i+1)])\n",
    "\n",
    "    def update(self, learning_rate = 1e-3):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ReLU): continue\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.__call__(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    \"\"\"\n",
    "    Computes the softmax activation followed by the cross-entropy loss.\n",
    "\n",
    "    It also calculates the gradient of the loss with respect to the input (x) for backpropagation.\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[1]\n",
    "    exp_scores = np.exp(x)\n",
    "\n",
    "    probs = exp_scores / exp_scores.sum(axis=0)\n",
    "    preds = probs.copy()\n",
    "\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat)) / batch_size\n",
    "\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1\n",
    "    x.grad = probs.copy()\n",
    "\n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epochs, mb_size=128, learning_rate=1e-3):\n",
    "  \"\"\"\n",
    "  Trains the model for a specified number of epochs using minibatches.\n",
    "\n",
    "  For each minibatch, it performs a forward pass, computes the loss, performs backpropagation, \n",
    "  and updates the model's parameters. After each epoch, the current cost and accuracy are printed.\n",
    "  \"\"\"\n",
    "  for epoch in range(epochs):\n",
    "    for i, (x_batch, y_batch) in enumerate(create_minibatches(mb_size, x_train, y_train)):\n",
    "      scores = model(x_batch.T.view(np_tensor))\n",
    "      _, cost = softmaxXEntropy(scores, y_batch)\n",
    "\n",
    "      model.backward()\n",
    "      model.update(learning_rate)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Cost: {cost}, Accuracy: {accuracy(x_val, y_val, mb_size)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y, mb_size):\n",
    "  \"\"\"\n",
    "  Calculates the accuracy of the model by comparing predictions to true labels.\n",
    "\n",
    "  It computes the percentage of correct predictions over the total number of samples.\n",
    "  \"\"\"\n",
    "  correct, total = 0, 0\n",
    "\n",
    "  for _, (x_batch, y_batch) in enumerate(create_minibatches(mb_size, x, y)):\n",
    "    pred = model(x_batch.T.view(np_tensor))\n",
    "    correct += np.sum(np.argmax(pred, axis=0) == y_batch.squeeze())\n",
    "    total += pred.shape[1]\n",
    "\n",
    "  return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your model and train it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input variables, using standard power of 2 number for the batching-size (although not really needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 512\n",
    "learning_rate = 1e-3\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the input size the same length as the image pixels, one neuron per pixel in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "layer_size = 784\n",
    "output_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture that include the previous formulas with the input, outputs and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential_layers([\n",
    "  Linear(input_size, layer_size),\n",
    "  ReLU(),\n",
    "  Linear(layer_size, layer_size),\n",
    "  ReLU(),\n",
    "  Linear(layer_size, output_size)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- mb size: 512 well enough\n",
    "- learning rate: this was the fastest but more accurate time learning rate\n",
    "- epoch: 30 gave us enogh room to get an 80% accuracy\n",
    "- input and layer size: both are the same so we can max out the input for all with the flattened grayscale image \n",
    "- output size: 24 as 24 letter of the alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen architecture and hyperparameters are well-suited for training on the dataset efficiently and effectively. A mini-batch size of 512 provides a balance between computational efficiency and stable gradient updates, while the learning rate was selected as the fastest value ensuring convergence without sacrificing accuracy. \n",
    "\n",
    "Training for 30 epochs allowed the model to achieve approximately 80% accuracy without overfitting.\n",
    "\n",
    "\n",
    "The input size matches the flattened grayscale image dimensions, ensuring all features are fully utilized, and the layer size matches the input size to maximize learning capacity across layers.\n",
    "\n",
    "The output size of 24 corresponds to the number of alphabet letters, enabling direct classification. \n",
    "\n",
    "The architecture consists of an initial `Linear` layer to map the input to a meaningful feature space, followed by `ReLU` activation for non-linear transformations, a second `Linear` layer to refine these features, another `ReLU` for preserving non-linearity, and a final `Linear` layer to map the processed features to 24 output classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model on random data from your test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training loop for 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Cost: 0.1149689171703088, Accuracy: 0.783324037925265\n",
      "Epoch 2, Cost: 0.01524977743754943, Accuracy: 0.805633017289459\n",
      "Epoch 3, Cost: 0.008967209057028679, Accuracy: 0.8053541550474066\n",
      "Epoch 4, Cost: 0.006548908352766799, Accuracy: 0.8081427774679308\n",
      "Epoch 5, Cost: 0.0044889518301248375, Accuracy: 0.8087005019520357\n",
      "Epoch 6, Cost: 0.003535997182632247, Accuracy: 0.8112102621305075\n",
      "Epoch 7, Cost: 0.003097835907069203, Accuracy: 0.8120468488566648\n",
      "Epoch 8, Cost: 0.0022740561684846264, Accuracy: 0.8120468488566648\n",
      "Epoch 9, Cost: 0.002243483888049497, Accuracy: 0.8131622978248745\n",
      "Epoch 10, Cost: 0.0019400243815978085, Accuracy: 0.8153931957612939\n",
      "Epoch 11, Cost: 0.0016769557221001583, Accuracy: 0.8153931957612939\n",
      "Epoch 12, Cost: 0.001352817788030561, Accuracy: 0.8179029559397658\n",
      "Epoch 13, Cost: 0.0011376726262969593, Accuracy: 0.8187395426659231\n",
      "Epoch 14, Cost: 0.0011637961370423611, Accuracy: 0.8192972671500279\n",
      "Epoch 15, Cost: 0.001030888746933828, Accuracy: 0.82069157836029\n",
      "Epoch 16, Cost: 0.0009403363347516934, Accuracy: 0.8212493028443949\n",
      "Epoch 17, Cost: 0.0010053500207881654, Accuracy: 0.8201338538761852\n",
      "Epoch 18, Cost: 0.0007711977168289619, Accuracy: 0.8212493028443949\n",
      "Epoch 19, Cost: 0.0007277559153937447, Accuracy: 0.8201338538761852\n",
      "Epoch 20, Cost: 0.0007100328977373797, Accuracy: 0.8201338538761852\n",
      "Epoch 21, Cost: 0.0006368250381234147, Accuracy: 0.822643614054657\n",
      "Epoch 22, Cost: 0.0007645216413600884, Accuracy: 0.8198549916341328\n",
      "Epoch 23, Cost: 0.0006410577715407394, Accuracy: 0.822643614054657\n",
      "Epoch 24, Cost: 0.0005792080726718858, Accuracy: 0.822643614054657\n",
      "Epoch 25, Cost: 0.000637441677481618, Accuracy: 0.8232013385387619\n",
      "Epoch 26, Cost: 0.00045148201367956487, Accuracy: 0.8215281650864473\n",
      "Epoch 27, Cost: 0.00039205025786283196, Accuracy: 0.8229224762967094\n",
      "Epoch 28, Cost: 0.0006088669007995324, Accuracy: 0.822643614054657\n",
      "Epoch 29, Cost: 0.0004222718545253834, Accuracy: 0.8259899609592861\n",
      "Epoch 30, Cost: 0.0005118277580241331, Accuracy: 0.8251533742331288\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: %81.31622978248745\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: %{accuracy(x_test, y_test, mb_size) * 100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For displaying the result, standarize the making all the chars lower case and removing j and z letters again (as the model won't include for those two letters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: f, Actual label: f\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(y_test))\n",
    "\n",
    "plot_image(x_test[idx])\n",
    "\n",
    "pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "pred_char = alphabet[pred]\n",
    "actual_char = alphabet[y_test[idx]]\n",
    "\n",
    "print(f\"Predicted label: {pred_char}, Actual label: {actual_char}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
