{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9",
   "metadata": {},
   "source": [
    "## TC 5033\n",
    "## Deep Learning\n",
    "## Transformers\n",
    "\n",
    "#### Activity 4: Implementing a Translator\n",
    "\n",
    "- Objective\n",
    "\n",
    "To understand the Transformer Architecture by Implementing a translator.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n",
    "\n",
    "    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n",
    "  \n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Traning a translator\n",
    "    - Translating at least 10 sentences.\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f54c65",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Script to convert csv to text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d5dcf681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1069fb910>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8f02c0c2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = './data/eng-spa2024.csv'\n",
    "TXT_INPUT_PATH = './data/eng-spa4.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6c169",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We load the dataset, clean it, and sort the English-Spanish sentence pairs by length. This helps improve training efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "787d9408",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/mq9yd779097d0kvtn4rhg2480000gq/T/ipykernel_36842/4248687483.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_PATH, sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "eng_spa_cols = df.iloc[:, [1, 3]]\n",
    "eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()  \n",
    "eng_spa_cols = eng_spa_cols.sort_values(by='length')  \n",
    "eng_spa_cols = eng_spa_cols.drop(columns=['length'])  \n",
    "\n",
    "eng_spa_cols.to_csv(TXT_INPUT_PATH, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d468e9a",
   "metadata": {},
   "source": [
    "## Transformer - Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06afbe",
   "metadata": {},
   "source": [
    "In this notebook, we implement a Transformer model from scratch for English-to-Spanish translation. We'll follow these steps:\n",
    "\n",
    "1. **Positional Encoding and Attention Mechanism**\n",
    "2. **Building the Transformer Model**\n",
    "3. **Training the Model**\n",
    "4. **Evaluating Translations**\n",
    "\n",
    "We are using PyTorch and a limited dataset for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2c2cbd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9c6623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6076228",
   "metadata": {},
   "source": [
    "### Positional Encoding and Self-Attention\n",
    "\n",
    "We implement the core building blocks of the Transformer:\n",
    "\n",
    "- **Positional Encoding**: Adds positional information to the word embeddings.\n",
    "- **Multi-Head Self-Attention**: Captures relationships between words.\n",
    "- **Feed Forward Network**: Helps with complex feature extraction.\n",
    "\n",
    "The following code defines these components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103d45f",
   "metadata": {
    "code_folding": [
     30,
     94
    ]
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements positional encoding for transformer models to inject\n",
    "    information about the position of tokens in a sequence.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimension of the embedding vector.\n",
    "        max_seq_len (int): Maximum length of the input sequence.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Positional encoding added to the input embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_seq_len=512):\n",
    "        super().__init__()\n",
    "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model)\n",
    "        token_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
    "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
    "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass that adds positional encoding to input embeddings.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (sequence_length, batch_size, d_model).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Positionally encoded input tensor.\n",
    "        \"\"\"\n",
    "        return x + self.pos_embed_matrix[:x.size(0), :]\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Multi-Head Attention mechanism.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimension of the input embeddings.\n",
    "        num_heads (int): Number of attention heads.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Weighted output and attention scores.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=512, num_heads=8):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, 'Embedding size not compatible with num heads'\n",
    "\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for multi-head attention.\n",
    "\n",
    "        Args:\n",
    "            Q (Tensor): Query tensor.\n",
    "            K (Tensor): Key tensor.\n",
    "            V (Tensor): Value tensor.\n",
    "            mask (Tensor, optional): Masking tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Weighted output and attention scores.\n",
    "        \"\"\"\n",
    "        batch_size = Q.size(0)\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n",
    "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "\n",
    "        return self.W_o(weighted_values), attention\n",
    "\n",
    "    def scale_dot_product(self, Q, K, V, mask=None):\n",
    "        \"\"\"\n",
    "        Scaled dot-product attention calculation.\n",
    "\n",
    "        Args:\n",
    "            Q (Tensor): Query tensor.\n",
    "            K (Tensor): Key tensor.\n",
    "            V (Tensor): Value tensor.\n",
    "            mask (Tensor, optional): Masking tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Weighted values and attention scores.\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        weighted_values = torch.matmul(attention, V)\n",
    "        return weighted_values, attention\n",
    "\n",
    "\n",
    "class PositionFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Feed Forward Neural Network within the Transformer.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Input and output dimension.\n",
    "        d_ff (int): Hidden layer dimension.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output after feedforward transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the feed-forward network.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Transformed output.\n",
    "        \"\"\"\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "\n",
    "class EncoderSubLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents a single Encoder sub-layer with Self-Attention and Feed Forward.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimension of the model.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        d_ff (int): Dimension of the feed-forward network.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the encoder sub-layer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "            mask (Tensor, optional): Masking tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output after self-attention and feed-forward network.\n",
    "        \"\"\"\n",
    "        attention_output, _ = self.self_attn(x, x, x, mask)\n",
    "        x = x + self.dropout1(attention_output)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout2(self.ffn(x))\n",
    "        return self.norm2(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Encoder consisting of multiple Encoder layers.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimension of the model.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        d_ff (int): Dimension of the feed-forward network.\n",
    "        num_layers (int): Number of encoder layers.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor.\n",
    "            mask (Tensor, optional): Masking tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized output of the final encoder layer.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class DecoderSubLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents a single Decoder sub-layer with Self-Attention, Cross-Attention, and Feed Forward.\n",
    "\n",
    "    This class defines a single sub-layer of the Transformer Decoder. It consists of:\n",
    "    1. Self-Attention: A multi-head self-attention mechanism that allows the decoder to focus on different parts of the input sequence.\n",
    "    2. Cross-Attention: A multi-head attention mechanism that allows the decoder to attend to the encoder's output.\n",
    "    3. Feed Forward: A position-wise feed-forward network that processes the output from the attention layers.\n",
    "    Each of these components is followed by Layer Normalization and Dropout for regularization.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
    "        \"\"\"\n",
    "        Performs the forward pass through the Decoder sub-layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "            encoder_output (torch.Tensor): The output from the encoder.\n",
    "            target_mask (torch.Tensor, optional): Mask for the target sequence.\n",
    "            encoder_mask (torch.Tensor, optional): Mask for the encoder's input.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The processed output of the Decoder sub-layer.\n",
    "        \"\"\"\n",
    "        x = self.norm1(x + self.dropout1(self.self_attn(x, x, x, target_mask)[0]))\n",
    "        x = self.norm2(x + self.dropout2(self.cross_attn(x, encoder_output, encoder_output, encoder_mask)[0]))\n",
    "        return self.norm3(x + self.dropout3(self.feed_forward(x)))\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Decoder consisting of multiple Decoder layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
    "        \"\"\"\n",
    "        Passes the input through all Decoder layers.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor.\n",
    "            encoder_output (torch.Tensor): The output from the encoder.\n",
    "            target_mask (torch.Tensor): Mask for the target sequence.\n",
    "            encoder_mask (torch.Tensor): Mask for the encoder's input.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final output after passing through all Decoder layers.\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
    "        return self.norm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afabcaf",
   "metadata": {},
   "source": [
    "### Transformer Model Architecture\n",
    "\n",
    "The Transformer consists of:\n",
    "\n",
    "- **Encoder**: Extracts features from the input sentence.\n",
    "- **Decoder**: Generates the target sentence.\n",
    "- **Embedding Layers**: Convert words to dense vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61070162",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer model that consists of an Encoder and Decoder.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimension of the model.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        d_ff (int): Dimension of the feed-forward network.\n",
    "        num_layers (int): Number of encoder and decoder layers.\n",
    "        input_vocab_size (int): Size of the input vocabulary.\n",
    "        target_vocab_size (int): Size of the target vocabulary.\n",
    "        max_len (int): Maximum sequence length.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers,\n",
    "                 input_vocab_size, target_vocab_size, \n",
    "                 max_len=512, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the Transformer model.\n",
    "\n",
    "        Args:\n",
    "            d_model (int): Dimension of the model.\n",
    "            num_heads (int): Number of attention heads.\n",
    "            d_ff (int): Dimension of the feed-forward network.\n",
    "            num_layers (int): Number of encoder and decoder layers.\n",
    "            input_vocab_size (int): Size of the input vocabulary.\n",
    "            target_vocab_size (int): Size of the target vocabulary.\n",
    "            max_len (int): Maximum sequence length.\n",
    "            dropout (float): Dropout rate.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
    "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        \"\"\"\n",
    "        Performs the forward pass of the Transformer model. Applies target\n",
    "        embedding and positional encoding that pass through the decoder.\n",
    "\n",
    "        Args:\n",
    "            source (Tensor): Input sequence tensor.\n",
    "            target (Tensor): Target sequence tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output logits for the target vocabulary.\n",
    "        \"\"\"\n",
    "        source_mask, target_mask = self.mask(source, target)\n",
    "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
    "        source = self.pos_embedding(source)\n",
    "        encoder_output = self.encoder(source, source_mask)\n",
    "\n",
    "        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n",
    "        target = self.pos_embedding(target)\n",
    "        output = self.decoder(target, encoder_output, target_mask, source_mask)\n",
    "\n",
    "        return self.output_layer(output)\n",
    "\n",
    "    def mask(self, source, target):\n",
    "        \"\"\"\n",
    "        Creates masks for the source and target sequences.\n",
    "\n",
    "        Args:\n",
    "            source (Tensor): Input source sequence.\n",
    "            target (Tensor): Input target sequence.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Tensor, Tensor]: Source mask and target mask.\n",
    "        \"\"\"\n",
    "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
    "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
    "        size = target.size(1)\n",
    "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
    "        target_mask = target_mask & no_mask\n",
    "\n",
    "        return source_mask, target_mask  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6b2d4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d40581d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len_source = 10\n",
    "seq_len_target = 10\n",
    "batch_size = 2\n",
    "input_vocab_size = 50\n",
    "target_vocab_size = 50\n",
    "\n",
    "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n",
    "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fc7cf689",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "\n",
    "model = Transformer(d_model, num_heads, d_ff, num_layers,\n",
    "                  input_vocab_size, target_vocab_size, \n",
    "                  max_len=MAX_SEQ_LEN, dropout=0.1)\n",
    "\n",
    "model = model.to(device)\n",
    "source = source.to(device)\n",
    "target = target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4618560e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = model(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ab0bc69d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput.shape torch.Size([2, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
    "print(f'ouput.shape {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b2910",
   "metadata": {},
   "source": [
    "### Translator Eng-Spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af1eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TXT_INPUT_PATH, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c930226f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Go.', 'Ve.'],\n",
       " ['No.', 'No.'],\n",
       " ['Ok!', '¡OK!'],\n",
       " ['Hi.', 'Hola.'],\n",
       " ['Ah!', '¡Anda!'],\n",
       " ['Hi.', '¡Hola!'],\n",
       " ['Go!', '¡Ve!'],\n",
       " ['Go!', '¡Sal!'],\n",
       " ['So?', '¿Y?'],\n",
       " ['Go!', '¡Ya!']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_spa_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "095f4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
    "spa_sentences = [pair[1] for pair in eng_spa_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0d9e1c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.', 'No.', 'Ok!', 'Hi.', 'Ah!', 'Hi.', 'Go!', 'Go!', 'So?', 'Go!']\n",
      "['Ve.', 'No.', '¡OK!', 'Hola.', '¡Anda!', '¡Hola!', '¡Ve!', '¡Sal!', '¿Y?', '¡Ya!']\n"
     ]
    }
   ],
   "source": [
    "print(eng_sentences[:10])\n",
    "print(spa_sentences[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d11478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocesses the input sentence by:\n",
    "    1. Converting it to lowercase.\n",
    "    2. Removing extra spaces and accented characters.\n",
    "    3. Keeping only lowercase letters.\n",
    "    4. Adding <sos> and <eos> tokens to the start and end.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "\n",
    "    Returns:\n",
    "        str: The preprocessed sentence with <sos> and <eos> tokens.\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
    "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
    "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
    "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
    "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
    "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<sos> ' + sentence + ' <eos>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "478f673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '¿Hola @ cómo estás? 123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "96ac79c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hola @ cómo estás? 123\n",
      "<sos> hola como estas <eos>\n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(preprocess_sentence(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d9fc9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
    "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f7a3b18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> ve <eos>',\n",
       " '<sos> no <eos>',\n",
       " '<sos> ok <eos>',\n",
       " '<sos> hola <eos>',\n",
       " '<sos> anda <eos>',\n",
       " '<sos> hola <eos>',\n",
       " '<sos> ve <eos>',\n",
       " '<sos> sal <eos>',\n",
       " '<sos> y <eos>',\n",
       " '<sos> ya <eos>']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97931cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    \"\"\"\n",
    "    Builds vocabulary from a list of sentences.\n",
    "\n",
    "    This function creates two mappings:\n",
    "    1. `word2idx`: A dictionary mapping words to unique indices (starting from 2).\n",
    "    2. `idx2word`: A dictionary mapping indices back to words.\n",
    "\n",
    "    Special tokens `<pad>` (0) and `<unk>` (1) are added to the vocabulary.\n",
    "\n",
    "    Args:\n",
    "        sentences (list of str): A list of sentences (each sentence is a string).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two dictionaries:\n",
    "            - word2idx (dict): Mapping from words to indices.\n",
    "            - idx2word (dict): Mapping from indices to words.\n",
    "    \"\"\"\n",
    "    words = [word for sentence in sentences for word in sentence.split()]\n",
    "    word_count = Counter(words)\n",
    "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7fa8738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
    "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n",
    "eng_vocab_size = len(eng_word2idx)\n",
    "spa_vocab_size = len(spa_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "79d6b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27934 47343\n"
     ]
    }
   ],
   "source": [
    "print(eng_vocab_size, spa_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngSpaDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A dataset class for English-Spanish sentence pairs.\n",
    "\n",
    "    This class is used to handle a collection of English and Spanish sentence pairs,\n",
    "    and provides methods to retrieve the sentences as index sequences based on the \n",
    "    provided word-to-index mappings for both languages.\n",
    "\n",
    "    Args:\n",
    "        eng_sentences (list of str): A list of English sentences.\n",
    "        spa_sentences (list of str): A list of Spanish sentences.\n",
    "        eng_word2idx (dict): A dictionary mapping English words to indices.\n",
    "        spa_word2idx (dict): A dictionary mapping Spanish words to indices.\n",
    "    \"\"\"\n",
    "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
    "        self.eng_sentences = eng_sentences\n",
    "        self.spa_sentences = spa_sentences\n",
    "        self.eng_word2idx = eng_word2idx\n",
    "        self.spa_word2idx = spa_word2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of sentence pairs in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of English-Spanish sentence pairs.\n",
    "        \"\"\"\n",
    "        return len(self.eng_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the English and Spanish sentences at the specified index as token indices.\n",
    "\n",
    "        This method splits the sentences into words, looks up their corresponding indices in \n",
    "        the word-to-index mappings, and returns the indices as tensors.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sentence pair to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple of two tensors:\n",
    "                - The first tensor contains the English sentence as token indices.\n",
    "                - The second tensor contains the Spanish sentence as token indices.\n",
    "        \"\"\"\n",
    "        eng_sentence = self.eng_sentences[idx]\n",
    "        spa_sentence = self.spa_sentences[idx]\n",
    "\n",
    "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
    "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
    "        \n",
    "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads and prepares a batch of English-Spanish sentence pairs.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuples): A list of sentence pairs, where each tuple contains:\n",
    "            - English sentence as tensor of word indices.\n",
    "            - Spanish sentence as tensor of word indices.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two tensors containing padded English and Spanish sentences.\n",
    "    \"\"\"\n",
    "    eng_batch, spa_batch = zip(*batch)\n",
    "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
    "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
    "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
    "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
    "    return eng_batch, spa_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283911d",
   "metadata": {},
   "source": [
    "### Training the Transformer\n",
    "\n",
    "We train the model using Cross-Entropy Loss and Adam Optimizer. The model will learn to translate from English to Spanish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d514b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, optimiser, epochs):\n",
    "    \"\"\"\n",
    "    Trains the model for a specified number of epochs.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to be trained.\n",
    "        dataloader (DataLoader): The DataLoader providing batches of data.\n",
    "        loss_function (callable): The loss function used to calculate loss.\n",
    "        optimiser (Optimizer): The optimizer used to update model parameters.\n",
    "        epochs (int): The number of epochs to train the model.\n",
    "\n",
    "    Prints:\n",
    "        The average loss for each epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 \n",
    "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
    "            eng_batch = eng_batch.to(device)\n",
    "            spa_batch = spa_batch.to(device)\n",
    "\n",
    "            target_input = spa_batch[:, :-1]\n",
    "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            output = model(eng_batch, target_input)\n",
    "            output = output.view(-1, output.size(-1))\n",
    "\n",
    "            loss = loss_function(output, target_output)\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f'Epoch: {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2379ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e08eef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n",
    "                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n",
    "                    max_len=MAX_SEQ_LEN, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1181a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "14e265e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: 3.5813\n",
      "Epoch: 2/10, Loss: 2.1919\n",
      "Epoch: 3/10, Loss: 1.6944\n",
      "Epoch: 4/10, Loss: 1.3691\n",
      "Epoch: 5/10, Loss: 1.1197\n",
      "Epoch: 6/10, Loss: 0.9188\n",
      "Epoch: 7/10, Loss: 0.7543\n",
      "Epoch: 8/10, Loss: 0.6278\n",
      "Epoch: 9/10, Loss: 0.5335\n",
      "Epoch: 10/10, Loss: 0.4657\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, loss_function, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce83f3",
   "metadata": {},
   "source": [
    "### Evaluating Translations\n",
    "\n",
    "We test the model with a few English sentences and check the quality of the translations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50740746",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    \"\"\"\n",
    "    Converts a sentence into a list of word indices.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence.\n",
    "        word2idx (dict): A dictionary mapping words to indices.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of indices corresponding to the words in the sentence.\n",
    "    \"\"\"\n",
    "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
    "\n",
    "def indices_to_sentence(indices, idx2word):\n",
    "    \"\"\"\n",
    "    Converts a list of indices back into a sentence.\n",
    "\n",
    "    Args:\n",
    "        indices (list): A list of word indices.\n",
    "        idx2word (dict): A dictionary mapping indices to words.\n",
    "\n",
    "    Returns:\n",
    "        str: The reconstructed sentence from the indices.\n",
    "    \"\"\"\n",
    "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n",
    "\n",
    "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    \"\"\"\n",
    "    Translates a sentence from English to Spanish using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The trained translation model.\n",
    "        sentence (str): The English sentence to translate.\n",
    "        eng_word2idx (dict): A dictionary mapping English words to indices.\n",
    "        spa_idx2word (dict): A dictionary mapping Spanish indices to words.\n",
    "        max_len (int, optional): The maximum length of the translated sentence. Default is MAX_SEQ_LEN.\n",
    "        device (str, optional): The device to run the model on (e.g., 'cpu' or 'cuda'). Default is 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        str: The translated Spanish sentence.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input_indices = sentence_to_indices(sentence, eng_word2idx)\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    # Initialize the target tensor with <sos> token\n",
    "    tgt_indices = [spa_word2idx['<sos>']]\n",
    "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, tgt_tensor)\n",
    "            output = output.squeeze(0)\n",
    "            next_token = output.argmax(dim=-1)[-1].item()\n",
    "            tgt_indices.append(next_token)\n",
    "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "            if next_token == spa_word2idx['<eos>']:\n",
    "                break\n",
    "\n",
    "    return indices_to_sentence(tgt_indices, spa_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "  \"\"\"\n",
    "  Translates and prints sentences.\n",
    "\n",
    "  Args:\n",
    "      model (nn.Module): The trained model.\n",
    "      sentences (list of str): List of sentences to translate.\n",
    "      eng_word2idx (dict): English word-to-index dictionary.\n",
    "      spa_idx2word (dict): Spanish index-to-word dictionary.\n",
    "      max_len (int, optional): Max length of translated sentences. Default is MAX_SEQ_LEN.\n",
    "      device (str, optional): Device to run the model on. Default is 'cpu'.\n",
    "  \"\"\"\n",
    "  for sentence in sentences:\n",
    "    translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
    "    print(f'Input sentence: {sentence}')\n",
    "    print(f'Traducción: {translation}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0db72",
   "metadata": {
    "code_folding": [
     15
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: What happns with words tht are not properly writtn?\n",
      "Traducción: <sos> las palabras no se ven con que mira las palabras <eos>\n",
      "\n",
      "Input sentence: She plays the piano very well.\n",
      "Traducción: <sos> ella toca el piano muy bien <eos>\n",
      "\n",
      "Input sentence: We are going to the beach tomorrow.\n",
      "Traducción: <sos> ma ana nos vamos a la playa <eos>\n",
      "\n",
      "Input sentence: Can you help me, please?\n",
      "Traducción: <sos> puede ayudarme por favor <eos>\n",
      "\n",
      "Input sentence: This book is really interesting.\n",
      "Traducción: <sos> este libro es realmente interesante <eos>\n",
      "\n",
      "Input sentence: They traveled to Spain last year.\n",
      "Traducción: <sos> el a o pasado viajo a espa a <eos>\n",
      "\n",
      "Input sentence: I have never been to Japan.\n",
      "Traducción: <sos> no he estado nunca en japon <eos>\n",
      "\n",
      "Input sentence: What time is the meeting?\n",
      "Traducción: <sos> a que hora es la reunion <eos>\n",
      "\n",
      "Input sentence: My favorite color is blue.\n",
      "Traducción: <sos> el azul que me encanta es mi color favorito <eos>\n",
      "\n",
      "Input sentence: The cat is sleeping on the couch.\n",
      "Traducción: <sos> el gato esta durmiendo en el sofa <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example sentences to test the translator\n",
    "test_sentences = [\n",
    "    \"What happns with words tht are not properly writtn?\",\n",
    "    \"She plays the piano very well.\",\n",
    "    \"We are going to the beach tomorrow.\",\n",
    "    \"Can you help me, please?\",\n",
    "    \"This book is really interesting.\",\n",
    "    \"They traveled to Spain last year.\",\n",
    "    \"I have never been to Japan.\",\n",
    "    \"What time is the meeting?\",\n",
    "    \"My favorite color is blue.\",\n",
    "    \"The cat is sleeping on the couch.\",\n",
    "]\n",
    "\n",
    "model = model.to(device)\n",
    "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f97c28e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874bcc59",
   "metadata": {},
   "source": [
    "The Transformer model for English-to-Spanish translation demonstrated promising potential, albeit with notable limitations due to the constrained dataset and compute power. The extensive training duration of 778 minutes underscored the computational demands of the architecture, showcasing that the model has aptitude for basic translations but struggled with complex structures, revealing signs of overfitting. Additionally, the model displayed difficulties in handling improperly written input, as seen in the following example:\n",
    "\n",
    "**Input sentence**: What happens with words that are not properly written?  \n",
    "**Traducción**: <sos> las palabras no se ven con que mira las palabras <eos>\n",
    "\n",
    "This translation is not proper, illustrating the model's challenges when encountering misspelled or poorly structured input, leading to incorrect or incomplete outputs.\n",
    "\n",
    "Some important points to consider:\n",
    "\n",
    "- The importance of efficient hardware to mitigate prolonged training times.\n",
    "- The value of diverse datasets to prevent overfitting.\n",
    "- The potential of utilizing pre-trained models and fine-tuning on more extensive datasets.\n",
    "- The benefits of harnessing hardware accelerators to enhance translation quality and reduce training time.\n",
    "\n",
    "This highlights the importance of efficient hardware to mitigate prolonged training times and the value of diverse datasets to prevent overfitting. Strategies such as utilizing pre-trained models, fine-tuning on more extensive datasets, and harnessing hardware accelerators could significantly enhance translation quality, reduce training time, and enable the model to generalize better across various linguistic contexts, including cases of misspelled or incomplete words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
