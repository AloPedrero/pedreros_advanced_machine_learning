{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940c6dbc",
   "metadata": {
    "id": "940c6dbc"
   },
   "source": [
    "## TC 5033\n",
    "### Word Embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
    "<br>\n",
    "\n",
    "- Objective:\n",
    "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
    "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
    "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Instructions:\n",
    "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested.\n",
    "\n",
    "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
    "\n",
    "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
    "\n",
    "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
    "\n",
    "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
    "\n",
    "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
    "\n",
    "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Evaluation Criteria:\n",
    "\n",
    "    - Correct setup of all the required libraries and modules (10%)\n",
    "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
    "    \n",
    "   - Functionality (60%):\n",
    "        - All the functions should execute without errors and provide the expected outputs.\n",
    "        - RNN model class (20%)\n",
    "        - Accuracy fucntion (10%)\n",
    "        - Training function (10%)\n",
    "        - Sampling function (10%)\n",
    "        - Confucion matrix (10%)\n",
    "\n",
    "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de318da",
   "metadata": {
    "id": "4de318da"
   },
   "source": [
    "Dataset\n",
    "\n",
    "https://pytorch.org/text/stable/datasets.html#text-classification\n",
    "\n",
    "https://paperswithcode.com/dataset/ag-news\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9801f9",
   "metadata": {
    "id": "4a9801f9"
   },
   "source": [
    "#### Install libraries (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9IUa6uRqQtGu",
   "metadata": {
    "id": "9IUa6uRqQtGu"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "878b524f",
   "metadata": {
    "executionInfo": {
     "elapsed": 7208,
     "status": "ok",
     "timestamp": 1730927094550,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "878b524f"
   },
   "outputs": [],
   "source": [
    "# The following libraries are required for running the given code\n",
    "# Please feel free to add any libraries you consider adecuate to complete the assingment.\n",
    "import numpy as np\n",
    "#PyTorch libraries\n",
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "# Dataloader library\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "# Libraries to prepare the data\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# neural layers\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# These libraries are suggested to plot confusion matrix\n",
    "# you may use others\n",
    "import scikitplot as skplt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bab55f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 159,
     "status": "ok",
     "timestamp": 1730927097048,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "3bab55f3",
    "outputId": "ceeb9cf1-327b-4c48-deda-c550651803ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38956d",
   "metadata": {
    "id": "3d38956d"
   },
   "source": [
    "### Get the train and the test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6b784",
   "metadata": {
    "id": "e9c6b784"
   },
   "source": [
    "Classes:\n",
    "\n",
    "* 1 - World\n",
    "\n",
    "* 2 - Sports\n",
    "\n",
    "* 3 - Business\n",
    "\n",
    "* 4 - Sci/Tech\n",
    "\n",
    "We will convert them to:\n",
    "\n",
    "* 0 - World\n",
    "\n",
    "* 1 - Sports\n",
    "\n",
    "* 2 - Business\n",
    "\n",
    "* 3 - Sci/Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49fbed19",
   "metadata": {
    "executionInfo": {
     "elapsed": 5438,
     "status": "ok",
     "timestamp": 1730927105127,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "49fbed19"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = AG_NEWS()\n",
    "train_dataset, test_dataset = to_map_style_dataset(train_dataset), to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c372eb9",
   "metadata": {
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1730927106939,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "9c372eb9"
   },
   "outputs": [],
   "source": [
    "# Get the tokeniser\n",
    "# tokeniser object\n",
    "tokeniser = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data):\n",
    "    for _, text in data:\n",
    "        yield tokeniser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "794d0375",
   "metadata": {
    "executionInfo": {
     "elapsed": 6165,
     "status": "ok",
     "timestamp": 1730927114676,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "794d0375"
   },
   "outputs": [],
   "source": [
    "# Build the vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
    "#set unknown token at position 0\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b48268d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1730927117331,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "b48268d4",
    "outputId": "f9c839a1-8598-41e9-c8a0-5e49ce5b5a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'tc5033'] [3314, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "#test tokens\n",
    "tokens = tokeniser('Welcome to TC5033')\n",
    "print(tokens, vocab(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8c8f6a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1730927118687,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "c8c8f6a6"
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN = int(len(train_dataset)*0.9)\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8290895e",
   "metadata": {
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1730927121582,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "8290895e"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(train_dataset, [NUM_TRAIN, NUM_VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbc75b54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1730927125276,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "cbc75b54",
    "outputId": "471ffecd-8d50-4c0b-8ad8-eab70f80c40d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000 12000 7600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eb459c7",
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1730927128564,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "5eb459c7"
   },
   "outputs": [],
   "source": [
    "labels =  [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "max_tokens = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffdbf077",
   "metadata": {
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1730927127379,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "ffdbf077"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    y, x = list(zip(*batch))\n",
    "\n",
    "    x = [vocab(tokeniser(text)) for text in x]\n",
    "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
    "\n",
    "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.int32) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a55e6ee",
   "metadata": {
    "executionInfo": {
     "elapsed": 178,
     "status": "ok",
     "timestamp": 1730927129681,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "0a55e6ee"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b98898",
   "metadata": {
    "id": "47b98898"
   },
   "source": [
    "### Let us build our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50f20793",
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1730927132530,
     "user": {
      "displayName": "José Antonio Cantoral Ceballos",
      "userId": "04961139803161381162"
     },
     "user_tz": 360
    },
    "id": "50f20793"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 300\n",
    "NEURONS = 128\n",
    "LAYERS = 2\n",
    "NUM_CLASSES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f7f5621",
   "metadata": {
    "id": "0f7f5621",
    "outputId": "673b7ec3-7261-4848-fd8f-e1116533a8ba"
   },
   "outputs": [],
   "source": [
    "class RecurrentModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
    "                                            embedding_dim=embed_size)\n",
    "\n",
    "        self.rnn = nn.GRU(input_size=embed_size,\n",
    "                          hidden_size=hidden,\n",
    "                          num_layers=layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding_layer(x)\n",
    "\n",
    "        rnn_out, _ = self.rnn(embedded)\n",
    "\n",
    "        final_hidden_state = rnn_out[:, -1, :]\n",
    "\n",
    "        out = self.fc(final_hidden_state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a42613f",
   "metadata": {
    "code_folding": [],
    "id": "2a42613f"
   },
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text, labels in loader:\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "            outputs = model(text)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e843e1f",
   "metadata": {
    "code_folding": [],
    "id": "5e843e1f"
   },
   "outputs": [],
   "source": [
    "def train(model, optimiser, epochs=100):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for text, labels in train_loader:\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "\n",
    "            labels = labels.long()\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            outputs = model(text)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Avereage loss: {average_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "87775b29",
   "metadata": {
    "id": "87775b29"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "rnn_model = RecurrentModel(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES)\n",
    "optimiser = torch.optim.Adam(rnn_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aec12a1b",
   "metadata": {
    "id": "aec12a1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5958\n",
      "Epoch [2/10], Loss: 0.2412\n",
      "Epoch [3/10], Loss: 0.1678\n",
      "Epoch [4/10], Loss: 0.1189\n",
      "Epoch [5/10], Loss: 0.0844\n",
      "Epoch [6/10], Loss: 0.0598\n",
      "Epoch [7/10], Loss: 0.0437\n",
      "Epoch [8/10], Loss: 0.0342\n",
      "Epoch [9/10], Loss: 0.0276\n",
      "Epoch [10/10], Loss: 0.0213\n"
     ]
    }
   ],
   "source": [
    "train(rnn_model, optimiser=optimiser,  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a3ef175",
   "metadata": {
    "id": "7a3ef175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9064\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy(rnn_model, test_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f25dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed30693d",
   "metadata": {
    "id": "ed30693d"
   },
   "outputs": [],
   "source": [
    "def sample_text(model, loader):\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text, labels in loader:\n",
    "            text, labels = text.to(device), labels.to(device)\n",
    "            outputs = model(text)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            for i in range(NUM_SAMPLES):\n",
    "                sample_text = \" \".join([vocab.get_itos()[idx] for idx in text[i].tolist() if idx != 0])\n",
    "                samples.append((sample_text, labels[i].item(), predicted[i].item()))\n",
    "            \n",
    "            break\n",
    "    \n",
    "    print(\"\\nPredictions:\")\n",
    "    for text, actual, pred in samples:\n",
    "        print(f\"Text: {text}\\nActual: {labels[actual]}\\nPredicted: {labels[pred]}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "534f0220",
   "metadata": {
    "id": "534f0220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "Text: making it look easy cleveland -- their membership in the nfl elite entitles the patriots to a gimme from time to time , like yesterday ' s 42-15 shellacking of the hapless cleveland browns .\n",
      "Actual: 2\n",
      "Predicted: 2\n",
      "\n",
      "\n",
      "Text: justices to debate mail-order wine being freelance wine critics may sound like a sweet gig , but ray and eleanor have soured on it . because their home state , michigan , blocks direct shipments from out-of-state\n",
      "Actual: 1\n",
      "Predicted: 0\n",
      "\n",
      "\n",
      "Text: panathinaikos 2 , arsenal 2 arsenal keeper jens lehmann was left red-faced in athens as two costly mistakes ensured that a champions league victory slipped through his side #39 s fingers again .\n",
      "Actual: 2\n",
      "Predicted: 2\n",
      "\n",
      "\n",
      "Text: iraq nuclear losses #39 a scandal #39 former un chief weapons inspector hans has said the loss of control of iraq #39 s nuclear sites by the us after it occupied the country was scandalous .\n",
      "Actual: 1\n",
      "Predicted: 1\n",
      "\n",
      "\n",
      "Text: oil prices set a new record above \\$50 singapore ( reuters ) - oil prices set a new record above \\$50 a barrel on tuesday as a prolonged u . s . production outage following hurricane ivan attracted fresh speculative buying .\n",
      "Actual: 1\n",
      "Predicted: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text(rnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38e093",
   "metadata": {
    "id": "bb38e093"
   },
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68107b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rnn_model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
